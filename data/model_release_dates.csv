"Model Name","Company","Release Date","Parameter Size","Open Source","Notes"
"GPT-4","OpenAI","2023-03-14","Not disclosed","No","Speculative size"
"GPT-4o","OpenAI","2024-05-13","Not disclosed","No","Multimodal"
"O1-preview","OpenAI","2024-09-12","Not disclosed","No","Proprietary, multimodal"
"O1-mini","OpenAI","2024-09-12","Not disclosed","No","Proprietary, multimodal"
"Sora","OpenAI","2024-12-09","Not disclosed","No","Multimodal AI model (text-to-video)"
"LLaMA","Meta","2023-02-24","7B, 13B, 30B, 65B","Yes","Initially restricted, later leaked"
"Llama 2","Meta","2023-07-18","7B, 13B, 70B","Yes","Open-source"
"Llama 3","Meta","2024-04-18","8B, 70B","Yes","Open-source"
"Llama 3.1","Meta","2024-07-23","8B, 70B, 405B","Yes","Open-source, largest model added"
"Llama 3.1 405B","Meta","2024-07-23","405B","Yes","128K token context, multilingual support"
"Grok-1","xAI","2023-11-04","314B","Yes","Open-sourced March 17, 2024"
"Grok-2","xAI","2024-08-12","Not specified","Unclear","Beta release"
"Claude 2","Anthropic","2023-07-11","Not disclosed","No","Proprietary"
"Claude 3 Opus","Anthropic","2024-03-04","Not disclosed","No","Proprietary"
"Claude 3.5 Sonnet","Anthropic","2024-06-20","Not disclosed","No","Proprietary"
"Claude 3.7 Sonnet","Anthropic","2025-02-24","Not disclosed","No","Proprietary"
"Qwen 1.5","Alibaba","2024-04-01","0.5B to 72B","Yes","Open-source"
"Qwen 2","Alibaba","2024-06-06","0.5B to 72B","Yes (some)","Mixed strategy"
"Qwen 2.5","Alibaba","2024-09-19","72B","Yes","Open-source"
"QwQ-32B-Preview","Alibaba","2024-11-29","32B","Yes","Open-source"
"Qwen 2.5-Max","Alibaba","2025-01-29","Not disclosed","Yes","Open-source"
"Qwen2.5-VL-32B-Instruct","Alibaba","2025-03-24","32B","Yes","Open-source, multimodal"
"Qwen2.5-Omni-7B","Alibaba","2025-03-26","7B","Yes","Open-source, multimodal"
"DeepSeek-V2","DeepSeek","2024-05-05","236B total, 21B activated","Yes","Open-source, MoE"
"DeepSeek-V3","DeepSeek","2024-12-26","671B total, 37B activated","Yes","Open-source, MoE"
"DeepSeek-R1","DeepSeek","2025-01-20","671B","Yes","Open-source"
"Command R","Cohere","2024-03-13","35B","Yes","Open-weight"
"Command R+","Cohere","2024-04-04","104B","Yes","Open-weight"
"Aya 23","CohereForAI","2024-05-21","8B, 35B","Yes","Open-weight research"
"Gemini 1.0","Google","2023-12-06","Not disclosed","No","Ultra, Pro, Nano variants"
"Gemini 1.5","Google","2024-02-15","Not disclosed","No","1M token context, Pro widely available April 2024"
"Gemini 2.0","Google","2024-12-01","Not disclosed","No","Pro and Flash variants, multimodal"
"Gemma 3","Google","2025-03-10","27B","Yes","Open-source"
"Mixtral 8x7B","Mistral AI","2023-12-08","56B total, 14B active","Yes","Open-source, MoE"
"Mistral Large","Mistral AI","2024-02-26","Not disclosed","No","Proprietary"
"Mixtral 8x22B","Mistral AI","2024-04-10","176","Yes","Open-source, MoE"
"Mistral Large 2","Mistral AI","2024-07-24","123B","No","Proprietary"
"Mistral Small 3","Mistral AI","2025-01-30","24B","Yes","Open-source"
"Pixtral-Large","Mistral AI","2024-11-18","124B","No","Proprietary, multimodal"